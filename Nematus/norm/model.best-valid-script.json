{
  "adam_beta1": 0.9,
  "adam_beta2": 0.98,
  "adam_epsilon": 1e-09,
  "batch_size": 256,
  "beam_freq": 0,
  "beam_size": 4,
  "clip_c": 1.0,
  "datasets": null,
  "decay_c": 0.0,
  "dictionaries": [
    "/home/user/gasser/norm/vocab.joint.json",
    "/home/user/gasser/norm/vocab.joint.json"
  ],
  "dim_per_factor": [
    512
  ],
  "disp_freq": 250,
  "embedding_size": 512,
  "exponential_smoothing": 0.0001,
  "factors": 1,
  "finish_after": 250000,
  "gradient_aggregation_steps": 1,
  "keep_train_set_in_memory": false,
  "label_smoothing": 0.3,
  "layer_normalization_type": "layernorm",
  "learning_rate": 0.0001,
  "learning_schedule": "transformer",
  "loss_function": "per-token-cross-entropy",
  "map_decay_c": 0.0,
  "max_epochs": 5000,
  "max_len_a": 1.5,
  "max_len_b": 5,
  "max_sentences_of_sampling": 0,
  "max_sentences_per_device": 0,
  "max_tokens_per_device": 4500,
  "maxibatch_size": 20,
  "maxlen": 200,
  "model_type": "transformer",
  "model_version": 0.2,
  "mrt_alpha": 0.005,
  "mrt_loss": "SENTENCEBLEU n=4",
  "mrt_ml_mix": 0,
  "mrt_reference": false,
  "n_best": false,
  "normalization_alpha": 0.6,
  "optimizer": "adam",
  "output_hidden_activation": "tanh",
  "patience": 5,
  "plateau_steps": 0,
  "preprocess_script": null,
  "print_per_token_pro": false,
  "prior_model": null,
  "reload": "latest_checkpoint",
  "reload_training_progress": true,
  "rnn_dec_base_transition_depth": 2,
  "rnn_dec_deep_context": false,
  "rnn_dec_depth": 1,
  "rnn_dec_high_transition_depth": 1,
  "rnn_dropout_embedding": 0.0,
  "rnn_dropout_hidden": 0.0,
  "rnn_dropout_source": 0.0,
  "rnn_dropout_target": 0.0,
  "rnn_enc_depth": 1,
  "rnn_enc_transition_depth": 1,
  "rnn_layer_normalization": false,
  "rnn_lexical_model": false,
  "rnn_use_dropout": true,
  "sample_freq": 0,
  "sample_way": "beam_search",
  "samplesN": 100,
  "sampling_temperature": 1.0,
  "save_freq": 30000,
  "saveto": "/home/user/gasser/norm/norm/model",
  "shuffle_each_epoch": true,
  "softmax_mixture_size": 1,
  "sort_by_length": true,
  "source_dataset": "/home/user/gasser/norm/train.src",
  "source_dicts": [
    "/home/user/gasser/norm/vocab.joint.json"
  ],
  "source_vocab_sizes": [
    3000
  ],
  "state_size": 512,
  "summary_dir": null,
  "summary_freq": 0,
  "target_dataset": "/home/user/gasser/norm/train.trg",
  "target_dict": "/home/user/gasser/norm/vocab.joint.json",
  "target_embedding_size": 512,
  "target_vocab_size": 3000,
  "theano_compat": false,
  "tie_decoder_embeddings": true,
  "tie_encoder_decoder_embeddings": true,
  "token_batch_size": 16384,
  "transformer_dec_depth": 2,
  "transformer_drophead": 0.0,
  "transformer_dropout_attn": 0.3,
  "transformer_dropout_embeddings": 0.2,
  "transformer_dropout_relu": 0.3,
  "transformer_dropout_residual": 0.3,
  "transformer_enc_depth": 2,
  "transformer_ffn_hidden_size": 2048,
  "transformer_num_heads": 4,
  "translation_maxlen": 200,
  "translation_strategy": "beam_search",
  "valid_batch_size": 120,
  "valid_bleu_source_dataset": "/home/user/gasser/norm/dev.src",
  "valid_datasets": null,
  "valid_freq": 250,
  "valid_script": "/home/user/gasser/scripts_copy/validate.sh",
  "valid_source_dataset": "/home/user/gasser/norm/dev.src",
  "valid_target_dataset": "/home/user/gasser/norm/dev.trg",
  "valid_token_batch_size": 4096,
  "warmup_steps": 4000
}
